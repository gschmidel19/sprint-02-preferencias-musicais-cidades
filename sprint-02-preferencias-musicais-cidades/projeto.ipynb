{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0vqbgi9ay0H"
   },
   "source": [
    "# Se liga na música"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhq_eyov_Zcs"
   },
   "source": [
    "# Conteúdo <a id='back'></a>\n",
    "\n",
    "* [Introdução](#intro)\n",
    "* [Etapa 1. Visão geral dos dados](#data_review)\n",
    "    * [Conclusões](#data_review_conclusions)\n",
    "* [Etapa 2. Pré-processamento de dados](#data_preprocessing)\n",
    "    * [2.1 Estilo do cabeçalho](#header_style)\n",
    "    * [2.2 Valores ausentes](#missing_values)\n",
    "    * [2.3 Duplicados](#duplicates)\n",
    "    * [2.4 Conclusões](#data_preprocessing_conclusions)\n",
    "* [Etapa 3. Teste da hipótese](#hypothesis)\n",
    "    * [3.1 Hipótese 1: atividade dos usuários nas duas cidades](#activity)\n",
    "* [Conclusões](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUC88oWjTJw2"
   },
   "source": [
    "## Introdução <a id='intro'></a>\n",
    "O trabalho de um analista é analisar dados para obter percepções valiosas dos dados e tomar decisões fundamentadas neles. Esse processo consiste em várias etapas, como visão geral dos dados, pré-processamento dos dados e testes de hipóteses.\n",
    "\n",
    "Sempre que fazemos uma pesquisa, precisamos formular uma hipótese que depois poderemos testar. Às vezes nós aceitamos essas hipóteses; outras vezes, nós as rejeitamos. Para fazer as escolhas certas, um negócio deve ser capaz de entender se está fazendo as suposições certas ou não.\n",
    "\n",
    "Neste projeto, você vai comparar as preferências musicais dos habitantes de Springfild e Shelbyville. Você vai estudar os dados de um serviço de streaming de música online para testar a hipótese apresentada abaixo e comparar o comportamento dos usuários dessas duas cidades.\n",
    "\n",
    "### Objetivo:\n",
    "Teste a hipótese:\n",
    "1. A atividade dos usuários é diferente dependendo do dia da semana e da cidade.\n",
    "\n",
    "\n",
    "### Etapas\n",
    "Os dados sobre o comportamento do usuário são armazenados no arquivo `/datasets/music_project_en.csv`. Não há informações sobre a qualidade dos dados, então será necessário examiná-los antes de testar a hipótese.\n",
    "\n",
    "Primeiro, você avaliará a qualidade dos dados e verá se seus problemas são significativos. Depois, durante o pré-processamento dos dados, você tentará tratar dos problemas mais críticos.\n",
    "\n",
    "O seu projeto consistirá em três etapas:\n",
    " 1. Visão geral dos dados\n",
    " 2. Pré-processamento de dados\n",
    " 3. Teste da hipótese\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDt6pg-Rw-1U"
   },
   "source": [
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml1hmfXC_Zcs"
   },
   "source": [
    "## Etapa 1. Visão geral dos dados <a id='data_review'></a>\n",
    "\n",
    "Abra os dados e examine-os."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57eAOGIz_Zcs"
   },
   "source": [
    "Você precisará da `pandas`, então, importe-a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AXN7PHPN_Zcs",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd# importando pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG23P8tt_Zcs"
   },
   "source": [
    "Leia o arquivo `music_project_en.csv` da pasta `/datasets/` e salve-o na variável `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fFVu7vqh_Zct",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/music_project_en.csv') # lendo o arquivo e armazenando em df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>Track</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>City</th>\n",
       "      <th>time</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFB692EC</td>\n",
       "      <td>Kamigata To Boots</td>\n",
       "      <td>The Mass Missile</td>\n",
       "      <td>rock</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:28:33</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55204538</td>\n",
       "      <td>Delayed Because of Accident</td>\n",
       "      <td>Andreas Rönnberg</td>\n",
       "      <td>rock</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>14:07:09</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20EC38</td>\n",
       "      <td>Funiculì funiculà</td>\n",
       "      <td>Mario Lanza</td>\n",
       "      <td>pop</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:58:07</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3DD03C9</td>\n",
       "      <td>Dragons in the Sunset</td>\n",
       "      <td>Fire + Ice</td>\n",
       "      <td>folk</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>08:37:09</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2DC1FAE</td>\n",
       "      <td>Soul People</td>\n",
       "      <td>Space Echo</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>08:34:34</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65074</th>\n",
       "      <td>729CBB09</td>\n",
       "      <td>My Name</td>\n",
       "      <td>McLean</td>\n",
       "      <td>rnb</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>13:32:28</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65075</th>\n",
       "      <td>D08D4A55</td>\n",
       "      <td>Maybe One Day (feat. Black Spade)</td>\n",
       "      <td>Blu &amp; Exile</td>\n",
       "      <td>hip</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65076</th>\n",
       "      <td>C5E3A0D5</td>\n",
       "      <td>Jalopiina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>industrial</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>20:09:26</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65077</th>\n",
       "      <td>321D0506</td>\n",
       "      <td>Freight Train</td>\n",
       "      <td>Chas McDevitt</td>\n",
       "      <td>rock</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>21:43:59</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65078</th>\n",
       "      <td>3A64EF84</td>\n",
       "      <td>Tell Me Sweet Little Lies</td>\n",
       "      <td>Monica Lopez</td>\n",
       "      <td>country</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>21:59:46</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65079 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID                              Track            artist  \\\n",
       "0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n",
       "1      55204538        Delayed Because of Accident  Andreas Rönnberg   \n",
       "2        20EC38                  Funiculì funiculà       Mario Lanza   \n",
       "3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n",
       "4      E2DC1FAE                        Soul People        Space Echo   \n",
       "...         ...                                ...               ...   \n",
       "65074  729CBB09                            My Name            McLean   \n",
       "65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n",
       "65076  C5E3A0D5                          Jalopiina               NaN   \n",
       "65077  321D0506                      Freight Train     Chas McDevitt   \n",
       "65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n",
       "\n",
       "            genre       City        time        Day  \n",
       "0            rock  Shelbyville  20:28:33  Wednesday  \n",
       "1            rock  Springfield  14:07:09     Friday  \n",
       "2             pop  Shelbyville  20:58:07  Wednesday  \n",
       "3            folk  Shelbyville  08:37:09     Monday  \n",
       "4           dance  Springfield  08:34:34     Monday  \n",
       "...           ...          ...       ...        ...  \n",
       "65074         rnb  Springfield  13:32:28  Wednesday  \n",
       "65075         hip  Shelbyville  10:00:00     Monday  \n",
       "65076  industrial  Springfield  20:09:26     Friday  \n",
       "65077        rock  Springfield  21:43:59     Friday  \n",
       "65078     country  Springfield  21:59:46     Friday  \n",
       "\n",
       "[65079 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDoOMd3uTqnZ"
   },
   "source": [
    "Imprima as primeiras 10 linhas da tabela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oWTVX3gW_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      userID                        Track               artist   genre  \\\n",
      "0   FFB692EC            Kamigata To Boots     The Mass Missile    rock   \n",
      "1   55204538  Delayed Because of Accident     Andreas Rönnberg    rock   \n",
      "2     20EC38            Funiculì funiculà          Mario Lanza     pop   \n",
      "3   A3DD03C9        Dragons in the Sunset           Fire + Ice    folk   \n",
      "4   E2DC1FAE                  Soul People           Space Echo   dance   \n",
      "5   842029A1                       Chains             Obladaet  rusrap   \n",
      "6   4CB90AA5                         True         Roman Messer   dance   \n",
      "7   F03E1C1F             Feeling This Way      Polina Griffith   dance   \n",
      "8   8FA1D3BE                     L’estate          Julia Dalia  ruspop   \n",
      "9   E772D5C0                    Pessimist                  NaN   dance   \n",
      "10  BC5A3A29                 Gool la Mita  Shireen Abdul Wahab   world   \n",
      "\n",
      "         City        time        Day  \n",
      "0   Shelbyville  20:28:33  Wednesday  \n",
      "1   Springfield  14:07:09     Friday  \n",
      "2   Shelbyville  20:58:07  Wednesday  \n",
      "3   Shelbyville  08:37:09     Monday  \n",
      "4   Springfield  08:34:34     Monday  \n",
      "5   Shelbyville  13:09:41     Friday  \n",
      "6   Springfield  13:00:07  Wednesday  \n",
      "7   Springfield  20:47:49  Wednesday  \n",
      "8   Springfield  09:17:40     Friday  \n",
      "9   Shelbyville  21:20:49  Wednesday  \n",
      "10  Springfield  14:08:42     Monday  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(11))# obtenha as 10 primeiras 10 linhas da tabela df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO73Kwic_Zct"
   },
   "source": [
    "Obtenha informações gerais sobre a tabela usando um comando. Você conhece o método para exibir informações gerais que precisamos obter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DSf2kIb-_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65079 entries, 0 to 65078\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0     userID  65079 non-null  object\n",
      " 1   Track     63736 non-null  object\n",
      " 2   artist    57512 non-null  object\n",
      " 3   genre     63881 non-null  object\n",
      " 4     City    65079 non-null  object\n",
      " 5   time      65079 non-null  object\n",
      " 6   Day       65079 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())# obtendo informações gerais sobre os nossos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaQ2Iwbr_Zct"
   },
   "source": [
    "Aqui estão as nossas observações sobre a tabela. Ela contém sete colunas. Elas armazenam o mesmo tipo de dado: `object`.\n",
    "\n",
    "De acordo com a documentação:\n",
    "- `' userID'` — identificação do usuário\n",
    "- `'Track'` — título da música\n",
    "- `'artist'` — nome do artista\n",
    "- `'genre'` — gênero da música\n",
    "- `'City'` — cidade do usuário\n",
    "- `'time'` — o tempo exato que a música foi reproduzida\n",
    "- `'Day'` — dia da semana\n",
    "\n",
    "Podemos ver três problemas de estilo nos cabeçalhos da tabela:\n",
    "1. Alguns cabeçalhos são escritos em letras maiúsculas, outros estão em minúsculas.\n",
    "2. Alguns cabeçalhos contêm espaços.\n",
    "3. `Detecte o problema e o descreva aqui`.\n",
    "\n",
    "problema 1. exsite espaços desnecessários na frente dos nomes das colunas;\n",
    "problema 2. existe uma diferença entre os nomes das colunas onde algumas tem a primeira letra maiuscula e outras minuscula\n",
    "problema 3. o \"userID\" deveria ser escrito da seguinte forma: user_id\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCB6-dXG_Zct"
   },
   "source": [
    "### Escreva suas observações. Aqui estão algumas perguntas que podem ajudar: <a id='data_review_conclusions'></a>\n",
    "\n",
    "`1.   Que tipo de dados temos nas linhas? E como podemos entender as colunas?`\n",
    "\n",
    "`2.   Esses dados são suficientes para responder à nossa hipótese ou precisamos de mais dados?`\n",
    "\n",
    "`3.   Você notou algum problema nos dados, como valores ausentes, duplicados ou tipos de dados errados`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eL__vcwViOi"
   },
   "source": [
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjYF6Ub9_Zct"
   },
   "source": [
    "## Etapa 2. Pré-processamento de dados <a id='data_preprocessing'></a>\n",
    "\n",
    "O objetivo aqui é preparar os dados para a análise.\n",
    "O primeiro passo é resolver todos os problemas com o cabeçalho. E então podemos passar para os valores ausentes e duplicados. Vamos começar.\n",
    "\n",
    "Corrija a formatação nos cabeçalhos da tabela.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaKXr29_Zct"
   },
   "source": [
    "### Estilo do cabeçalho <a id='header_style'></a>\n",
    "Imprima os cabeçalhos da tabela (os nomes das colunas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oKOTdF_Q_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)# imprima os nomes das colunas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj5534cv_Zct"
   },
   "source": [
    "Mude os cabeçalhos da tabela conforme as boas práticas de estilo:\n",
    "* Todos os caracteres precisam estar com letras minúsculas\n",
    "* Exclua espaços\n",
    "* Se o nome tiver várias palavras, use snake_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu0zkfe5zNJe"
   },
   "source": [
    "Anteriormente, você aprendeu sobre uma maneira automatizada de renomear colunas. Vamos usá-la agora. Use o ciclo for para percorrer os nomes das colunas e transformar todos os caracteres em letras minúsculas. Após fazer isso, imprima os cabeçalhos da tabela novamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6I_RwwMhzM4e",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()# Percorrendo os cabeçalhos e convertendo tudo em minúsculos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pweIRxjSzPYW"
   },
   "source": [
    "Agora, usando a mesma abordagem, exclua os espaços no início e no final de cada nome de coluna e imprima os nomes das colunas novamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vVQXbFyJzSYl",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '', regex=False)# Percorrendo os cabeçalhos e removendo os espaços\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCb8MW1JzURd"
   },
   "source": [
    "Precisamos aplicar a regra de sublinhado no lugar de espaço à coluna `userid`. Deveria ser `user_id`. Renomeie essa coluna e imprima os nomes de todas as colunas quando terminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ISlFqs5y_Zct",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'userID': 'user_id'})# Renomeando a coluna \"userid\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dqbh00J_Zct"
   },
   "source": [
    "Verifique o resultado. Imprima os cabeçalhos novamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "d4NOAmTW_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)# verificando o resultado: a lista de cabeçalhos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYJk6ksJVpOl"
   },
   "source": [
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ISfbcfY_Zct"
   },
   "source": [
    "### Valores Ausentes <a id='missing_values'></a>\n",
    " Primeiro, encontre a quantidade de valores ausentes na tabela. Você precisa usar dois métodos em sequência para obter o número de valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RskX29qr_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userid       0\n",
      "track     1343\n",
      "artist    7567\n",
      "genre     1198\n",
      "city         0\n",
      "time         0\n",
      "day          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "valores_ausentes_por_coluna = df.isnull().sum()\n",
    "print(valores_ausentes_por_coluna) # calculando o número de valores ausentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qubhgnlO_Zct"
   },
   "source": [
    "Nem todos os valores ausentes afetam a pesquisa. Por exemplo, os valores ausentes em `track` e `artist` não são críticos. Você pode simplesmente substituí-los por valores padrão, como a string `'unknown'`.\n",
    "\n",
    "Mas valores ausentes em `'genre'` podem afetar a comparação de preferências musicais de Springfield e Shelbyville. Na vida real, seria útil descobrir as razões pelas quais os dados estão ausentes e tentar corrigi-los. Mas nós não temos essa possibilidade neste projeto. Então, você terá que:\n",
    "* Preencha esses valores ausentes com um valor padrão\n",
    "* Avalie em que medida os valores ausentes podem afetar sua análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSv2laPA_Zct"
   },
   "source": [
    "Substitua os valores ausentes nas colunas `'track'`, `'artist'` e `'genre'` pela string `'unknown'`. Como mostramos nas lições anteriores, a melhor maneira de fazer isso é criar uma lista para armazenar os nomes das colunas nas quais precisamos fazer a substituição. Em seguida, use essa lista e percorra as colunas nas quais a substituição seja necessária e faça a substituição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KplB5qWs_Zct",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "df.fillna('unknown', inplace=True)# percorrendo os cabeçalhos e substituindo valores ausentes por 'unknown'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilsm-MZo_Zct"
   },
   "source": [
    "Agora verifique o resultado para ter certeza de que o conjunto de dados não contenha valores ausentes após a substituição. Para fazer isso, conte os valores ausentes novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Tq4nYRX4_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userid    0\n",
      "track     0\n",
      "artist    0\n",
      "genre     0\n",
      "city      0\n",
      "time      0\n",
      "day       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "valores_ausentes_por_coluna = df.isnull().sum()\n",
    "print(valores_ausentes_por_coluna)# contando os valores ausentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ZIBmq9VrsK"
   },
   "source": [
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWKRtBJ3_Zct"
   },
   "source": [
    "### Duplicados <a id='duplicates'></a>\n",
    "Encontre o número de duplicados explícitos na tabela. Lembre-se de que você precisa aplicar dois métodos em sequência para obter o número de duplicados explícitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "36eES_S0_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3826\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())# contando duplicados explícitos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot25h6XR_Zct"
   },
   "source": [
    "Agora descarte todos os duplicados. Para fazer isso, chame o método que faz exatamente isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "exFHq6tt_Zct",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)# removendo duplicados explícitos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im2YwBEG_Zct"
   },
   "source": [
    "Agora vamos verificar se descartamos todos os duplicados. Conte duplicados explícitos mais uma vez para ter certeza de que você removeu todos eles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-8PuNWQ0_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())# verificando duplicados novamente\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlFBsxAr_Zct"
   },
   "source": [
    "Agora queremos nos livrar dos duplicados implícitos na coluna `genre`. Por exemplo, o nome de um gênero pode ser escrito de maneiras diferentes. Alguns erros afetarão também o resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSjWwsOh_Zct"
   },
   "source": [
    "Para fazer isso, vamos começar imprimindo uma lista de nomes de gênero únicos, ordenados em ordem alfabética: Para fazer isso:\n",
    "* Extraia a coluna `genre` do DataFrame\n",
    "* Chame o método que retornará todos os valores únicos na coluna extraída\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "JIUcqzZN_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n",
      " 'unknown' 'alternative' 'children' 'rnb' 'hip' 'jazz' 'postrock' 'latin'\n",
      " 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental' 'rusrock'\n",
      " 'dnb' 'türk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'hiphop' 'drum' 'extrememetal' 'türkçe'\n",
      " 'experimental' 'easy' 'metalcore' 'modern' 'argentinetango' 'old' 'swing'\n",
      " 'breaks' 'eurofolk' 'stonerrock' 'industrial' 'funk' 'middle' 'variété'\n",
      " 'other' 'adult' 'christian' 'thrash' 'gothic' 'international' 'muslim'\n",
      " 'relax' 'schlager' 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage'\n",
      " 'specialty' 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power'\n",
      " 'death' 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european'\n",
      " 'tech' 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera'\n",
      " 'celtic' 'tradjazz' 'acoustic' 'epicmetal' 'hip-hop' 'historisch'\n",
      " 'downbeat' 'downtempo' 'africa' 'audiobook' 'jewish' 'sängerportrait'\n",
      " 'deutschrock' 'eastern' 'action' 'future' 'electropop' 'folklore'\n",
      " 'bollywood' 'marschmusik' 'rnr' 'karaoke' 'indian' 'rancheras'\n",
      " 'afrikaans' 'rhythm' 'sound' 'deutschspr' 'trip' 'lovers' 'choral'\n",
      " 'dancepop' 'retro' 'smooth' 'mexican' 'brazilian' 'ïîï' 'mood' 'surf'\n",
      " 'gangsta' 'inspirational' 'idm' 'ethnic' 'bluegrass' 'broadway'\n",
      " 'animated' 'americana' 'karadeniz' 'rockabilly' 'colombian' 'self' 'hop'\n",
      " 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport' 'ragga' 'traditional'\n",
      " 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop' 'glitch' 'documentary'\n",
      " 'oceania' 'popeurodance' 'dark' 'vi' 'grunge' 'hardstyle' 'samba'\n",
      " 'garage' 'art' 'folktronica' 'entehno' 'mediterranean' 'chamber' 'cuban'\n",
      " 'taraftar' 'gypsy' 'hardtechno' 'shoegazing' 'bossa' 'latino' 'worldbeat'\n",
      " 'malaysian' 'baile' 'ghazal' 'arabic' 'popelectronic' 'acid' 'kayokyoku'\n",
      " 'neoklassik' 'tribal' 'tanzorchester' 'native' 'independent' 'cantautori'\n",
      " 'handsup' 'punjabi' 'synthpop' 'rave' 'französisch' 'quebecois' 'speech'\n",
      " 'soulful' 'jam' 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow'\n",
      " 'jungle' 'indipop' 'axé' 'fado' 'showtunes' 'arena' 'irish' 'mandopop'\n",
      " 'forró' 'dirty' 'regional']\n"
     ]
    }
   ],
   "source": [
    "print(df['genre'].unique())# visualizando nomes de gêneros únicos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qej-Qmuo_Zct"
   },
   "source": [
    "Olhe a lista e encontre duplicados implícitos do gênero `hiphop`. Esses podem ser nomes escritos incorretamente, ou nomes alternativos para o mesmo gênero.\n",
    "\n",
    "Você verá os seguintes duplicados implícitos:\n",
    "* `hip`\n",
    "* `hop`\n",
    "* `hip-hop`\n",
    "\n",
    "Para se livrar deles, crie uma função `replace_wrong_genres()` com dois parâmetros:\n",
    "* `wrong_genres=` — essa é uma lista que contém todos os valores que você precisa substituir\n",
    "* `correct_genre=` — essa é uma string que você vai usar para a substituição\n",
    "\n",
    "Como resultado, a função deve corrigir os nomes na coluna `'genre'` da tabela `df`, isto é, substituindo cada valor da lista `wrong_genres` por valores de `correct_genre`.\n",
    "\n",
    "Dentro do corpo da função, use um ciclo `'for'` para percorrer a lista de gêneros errados, extrair a coluna `'genre'` e aplicar o método `replace` para fazer as correções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ErNDkmns_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic' nan\n",
      " 'alternative' 'children' 'rnb' 'hip-hop' 'jazz' 'postrock' 'latin'\n",
      " 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental' 'rusrock'\n",
      " 'dnb' 'türk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'hiphop' 'drum' 'extrememetal' 'türkçe'\n",
      " 'experimental' 'easy' 'metalcore' 'modern' 'argentinetango' 'old' 'swing'\n",
      " 'breaks' 'eurofolk' 'stonerrock' 'industrial' 'funk' 'middle' 'variété'\n",
      " 'other' 'adult' 'christian' 'thrash' 'gothic' 'international' 'muslim'\n",
      " 'relax' 'schlager' 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage'\n",
      " 'specialty' 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power'\n",
      " 'death' 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european'\n",
      " 'tech' 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera'\n",
      " 'celtic' 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat'\n",
      " 'downtempo' 'africa' 'audiobook' 'jewish' 'sängerportrait' 'deutschrock'\n",
      " 'eastern' 'action' 'future' 'electropop' 'folklore' 'bollywood'\n",
      " 'marschmusik' 'rnr' 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm'\n",
      " 'sound' 'deutschspr' 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth'\n",
      " 'mexican' 'brazilian' 'ïîï' 'mood' 'surf' 'gangsta' 'inspirational' 'idm'\n",
      " 'ethnic' 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz'\n",
      " 'rockabilly' 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge'\n",
      " 'sport' 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko'\n",
      " 'cantopop' 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi'\n",
      " 'grunge' 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n",
      " 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n",
      " 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n",
      " 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n",
      " 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n",
      " 'synthpop' 'rave' 'französisch' 'quebecois' 'speech' 'soulful' 'jam'\n",
      " 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n",
      " 'axé' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forró' 'dirty'\n",
      " 'regional']\n"
     ]
    }
   ],
   "source": [
    "def replace_wrong_genres(df, wrong_genres, correct_genre):\n",
    "    for genre in wrong_genres:\n",
    "              df['genre'] = df['genre'].replace(genre, correct_genre, regex=False)\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "wrong_genres = ['hip', 'hop', 'hip-hop']\n",
    "\n",
    "correct_genre = 'hip-hop'\n",
    "\n",
    "df = replace_wrong_genres(df, wrong_genres, correct_genre)\n",
    "\n",
    "print(df['genre'].unique())# função para substituir duplicados implícitos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDoBJxbA_Zct"
   },
   "source": [
    "Agora, chame a função `replace_wrong_genres()` e passe argumentos apropriados para que ela limpe duplicados implícitos (`hip`, `hop` e `hip-hop`) substituindo-os por `hiphop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "YN5i2hpmSo09",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "wrong_genres = ['hip', 'hop', 'hip-hop']\n",
    "\n",
    "correct_genre = 'hiphop'\n",
    "\n",
    "df = replace_wrong_genres(df, wrong_genres, correct_genre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQKF16_RG15m"
   },
   "source": [
    "Certifique-se que os nomes duplicados foram removidos. Imprima a lista de valores únicos da coluna `'genre'` mais uma vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wvixALnFG15m",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic' nan\n",
      " 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock' 'latin'\n",
      " 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental' 'rusrock'\n",
      " 'dnb' 'türk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'drum' 'extrememetal' 'türkçe' 'experimental' 'easy'\n",
      " 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n",
      " 'stonerrock' 'industrial' 'funk' 'middle' 'variété' 'other' 'adult'\n",
      " 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n",
      " 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n",
      " 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n",
      " 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n",
      " 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n",
      " 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n",
      " 'africa' 'audiobook' 'jewish' 'sängerportrait' 'deutschrock' 'eastern'\n",
      " 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n",
      " 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n",
      " 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n",
      " 'brazilian' 'ïîï' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n",
      " 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n",
      " 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n",
      " 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n",
      " 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n",
      " 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n",
      " 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n",
      " 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n",
      " 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n",
      " 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n",
      " 'synthpop' 'rave' 'französisch' 'quebecois' 'speech' 'soulful' 'jam'\n",
      " 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n",
      " 'axé' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forró' 'dirty'\n",
      " 'regional']\n"
     ]
    }
   ],
   "source": [
    "print(df['genre'].unique())# verificando valores duplicados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALgNbvF3VtPA"
   },
   "source": [
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz6a9-7HQUDd"
   },
   "source": [
    "### Suas observações <a id='data_preprocessing_conclusions'></a>\n",
    "\n",
    "` Descreva brevemente o que você reparou ao analisar duplicados, bem como a abordagem que usou para eliminá-los e os resultados que alcançou.`\n",
    "\n",
    "Abordagem utilizada para eliminar os duplicados:\n",
    "Identificação dos valores duplicados: Eu identifiquei que os gêneros apomtados \"hip\", \"hop\" e \"hip-hop\" eram o mesmo gênero musical, \"hiphop\", e poderiam ser substituídos.\n",
    "\n",
    "depois de muito bater cabeça eu optei por desenvolver a função replace_wrong_genres() que aceita dois parâmetros:\n",
    "\n",
    "wrong_genres: uma lista de gêneros errados a serem corrigidos.\n",
    "correct_genre: o gênero correto que substituirá os valores errados e utilizei o método .replace() para substituir cada ocorrência de gênero errado pela versão correta (neste caso, \"hiphop\").\n",
    "\n",
    "depois eu apliquei a função no DataFrame para corrigir todos os valores da coluna 'genre' que correspondiam a \"hip\", \"hop\" ou \"hip-hop\", substituindo-os por \"hiphop\".\n",
    "\n",
    "Resultados alcançados:\n",
    "todas as variantes foram uniformizados para \"hiphop\" resultando numa uniformização de nomeclatura que facilita a leitura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK1es74rVujj"
   },
   "source": [
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WttZHXH0SqKk"
   },
   "source": [
    "## Etapa 3. Teste da hipótese <a id='hypothesis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im936VVi_Zcu"
   },
   "source": [
    "### Hipótese: comparação do comportamento dos usuários nas duas cidades <a id='activity'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwt_MuaL_Zcu"
   },
   "source": [
    "A hipótese afirma que existem diferenças no consumo de música pelos usuários em Springfield e em Shelbyville. Para testar a hipótese, use os dados dos três dias da semana: segunda-feira (Monday), quarta-feira (Wednesday) e sexta-feira (Friday).\n",
    "\n",
    "* Agrupe os usuários por cidade.\n",
    "* Compare o número de músicas tocadas por cada grupo na segunda, quarta e sexta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dw_YMmT_Zcu"
   },
   "source": [
    "Execute cada cálculo separadamente.\n",
    "\n",
    "O primeiro passo é avaliar a atividade dos usuários em cada cidade. Não se esqueça das etapas \"divisão-aplicação-combinação\" sobre as quais falamos anteriormente na lição. Agora seu objetivo é agrupar os dados por cidade, aplicar o método de contagem apropriado durante a etapa de aplicação e então encontrar o número de músicas tocadas por cada grupo, especificando a coluna para a qual você quer obter a contagem.\n",
    "\n",
    "Veja um exemplo de como o resultado final deve ser:\n",
    "`df.groupby(by='....')['column'].method()` Execute cada cálculo separadamente.\n",
    "\n",
    "Para avaliar a atividade dos usuários em cada cidade, agrupe os dados por cidade e encontre o número de músicas reproduzidas em cada grupo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "0_Qs96oh_Zcu",
    "scrolled": true,
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n",
      "Shelbyville    19302\n",
      "Springfield    44434\n",
      "Name: track, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando o DataFrame\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(' ', '', regex=False)\n",
    "df = df.rename(columns={'userID': 'user_id'})\n",
    "\n",
    "\n",
    "df_groupby = df.groupby(by='city')['track'].count() # Contando as músicas tocadas em cada cidade\n",
    "\n",
    "#Criando função number_tracks    \n",
    "def number_tracks(df, day, city):# Declare a função number_tracks() com dois parâmetros: day= e city=\n",
    "    df_filtered_day = df[df['day'] == day]\n",
    "    df_filtered_city = df[df['city'] == city] # Armazene as linhas do DataFrame em que o valor na coluna 'day' é igual ao parâmetro day=\n",
    "    count_tracks = df_filtered_city['track'].count()\n",
    "\n",
    "    return count_tracks \n",
    "\n",
    "print(df_groupby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_Qx-3NewAnK"
   },
   "source": [
    "`Comente sobre suas observações aqui`\n",
    "\n",
    "primeiramente eu tive que gormatdas todos os nomes das colunas novamente, uma vez que eu nao estava conseguindo localizar o nome das colunas o que estava incorrendo em erro.\n",
    "\n",
    "depois apliquei a função df.groupby(['city', 'day'])para agrupar as colunas 'cidade' e 'dia'. \n",
    "\n",
    "novamente usei a função \"sum\" ['track'].sum(): Para cada grupo formado, somar o valor das músicas tocadas.\n",
    "\n",
    "print(resultado): Exibe o resultado, que vai mostrar a soma das músicas tocadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzli3w8o_Zcu"
   },
   "source": [
    "Agora vamos agrupar os dados por dia da semana e encontrar a quantidade de músicas tocadas na segunda, quarta e sexta-feira. Use a mesma abordagem que antes, mas agora precisamos agrupar os dados de uma forma diferente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "uZMKjiJz_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Músicas tocadas na segunda-feira: 22106\n",
      "Músicas tocadas na quarta-feira: 18862\n",
      "Músicas tocadas na sexta-feira: 22768\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando o DataFrame\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(' ', '', regex=False)\n",
    "df = df.rename(columns={'userID': 'user_id'})\n",
    "\n",
    "\n",
    "# Função para contar as músicas tocadas em um dia específico\n",
    "def number_tracks_by_day(df, day):\n",
    "    df_filtered_day = df[df['day'] == day]\n",
    "    count_tracks = df_filtered_day['track'].count()\n",
    "    \n",
    "    return count_tracks\n",
    "\n",
    "monday_tracks = number_tracks_by_day(df, 'Monday')\n",
    "wednesday_tracks = number_tracks_by_day(df, 'Wednesday')\n",
    "friday_tracks = number_tracks_by_day(df, 'Friday')\n",
    "\n",
    "\n",
    "print(f\"Músicas tocadas na segunda-feira: {monday_tracks}\")\n",
    "print(f\"Músicas tocadas na quarta-feira: {wednesday_tracks}\")\n",
    "print(f\"Músicas tocadas na sexta-feira: {friday_tracks}\")\n",
    "# Calculando as músicas escutadas em cada um desses três dias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC2tNrlL_Zcu"
   },
   "source": [
    "`Comente sobre suas observações aqui`\n",
    "\n",
    "Fiz a formatação das colunas igual ao topico anterior para poder trabalhar com as colunas de forma limpa.\n",
    "\n",
    "depois fiz a separação por cidade seguindo a logica o exercicio anterior e após fiz a separação por dias da semana e os imprimi separadamente para facilitar a visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POzs8bGa_Zcu"
   },
   "source": [
    "Você acabou de aprender como contar entradas agrupando-as por cidade ou por dia. E agora você precisa escrever uma função que possa contar entradas simultaneamente com base em ambos os critérios.\n",
    "\n",
    "Crie a função `number_tracks()` para calcular o número de músicas tocadas em um determinado dia **e** em uma determinada cidade. A função deve aceitar dois parâmetros:\n",
    "\n",
    "- `day`: um dia da semana pelo qual precisamos filtrar os dados. Por exemplo, `'Monday'`.\n",
    "- `city`: uma cidade pela qual precisamos filtrar os dados. Por exemplo, `'Springfield'`.\n",
    "\n",
    "Dentro da função, você vai aplicar uma filtragem consecutiva com indexação lógica.\n",
    "\n",
    "Primeiro, filtre os dados por dia e então filtre a tabela resultante por cidade.\n",
    "\n",
    "Depois de filtrar os dados usando os dois critérios, conte o número de valores na coluna 'user_id' da tabela resultante. O resultado da contagem representará o número de entradas que você quer encontrar. Armazene o resultado em uma nova variável e imprima-o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Nz3GdQB1_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do DataFrame: Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n",
      "Valores únicos em 'day': ['Wednesday' 'Friday' 'Monday']\n",
      "Valores únicos em 'city': ['Shelbyville' 'Springfield']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando o DataFrame\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(' ', '', regex=False)\n",
    "df = df.rename(columns={'userID': 'user_id'})\n",
    "\n",
    "print(\"Colunas do DataFrame:\", df.columns)\n",
    "print(\"Valores únicos em 'day':\", df['day'].unique())\n",
    "print(\"Valores únicos em 'city':\", df['city'].unique()) # fiz isso pra verificar se os dados estão corretos, em razão de dificuldade no a impressão dos dados.\n",
    "\n",
    "def number_tracks(df, day, city):# Declare a função number_tracks() com dois parâmetros: day= e city=.\n",
    "\n",
    "    df_filtered_day = df[df['day'] == day]# Armazene as linhas do DataFrame em que o valor na coluna 'day' é igual ao parâmetro day=\n",
    "\n",
    "    df_filtered_city = df_filtered_day[df_filtered_day['city'] == city]# Filtre as linhas em que o valor na coluna 'city' é igual ao parâmetro city=\n",
    "\n",
    "    count_tracks = df_filtered_city['userid'].count()# Extraia a coluna 'user_id' da tabela filtrada e aplique o método count()\n",
    "\n",
    "    print(f\"Número de entradas na coluna 'userid' em {city} na {day}: {count_tracks}\") # Retorne o número dos valores da coluna 'user_id'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytf7xFrFJQ2r"
   },
   "source": [
    "Chame a função `number_tracks()` seis vezes, mudando os valores dos parâmetros, para que você possa recuperar os dados de ambas as cidades para cada um dos três dias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "rJcRATNQ_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entradas na coluna 'userid' em Springfield na Monday: 16715\n"
     ]
    }
   ],
   "source": [
    "number_tracks(df, 'Monday', 'Springfield')# a quantidade de músicas tocadas em Springfield na segunda-feira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "hq_ncZ5T_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entradas na coluna 'userid' em Shelbyville na Monday: 5982\n"
     ]
    }
   ],
   "source": [
    "number_tracks(df, 'Monday', 'Shelbyville')# a quantidade de músicas tocadas em Shelbyville na segunda-feira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "_NTy2VPU_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entradas na coluna 'userid' em Springfield na Wednesday: 11755\n"
     ]
    }
   ],
   "source": [
    "number_tracks(df, 'Wednesday', 'Springfield')# a quantidade de músicas tocadas em Springfield na quarta-feira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "j2y3TAwo_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entradas na coluna 'userid' em Shelbyville na Wednesday: 7478\n"
     ]
    }
   ],
   "source": [
    "number_tracks(df, 'Wednesday', 'Shelbyville')# a quantidade de músicas tocadas em Shelbyville na quarta-feira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "vYDw5u_K_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entradas na coluna 'userid' em Springfield na Friday: 16890\n"
     ]
    }
   ],
   "source": [
    "number_tracks(df, 'Friday', 'Springfield')# a quantidade de músicas tocadas em Springfield na sexta-feira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "8_yzFtW3_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entradas na coluna 'userid' em Shelbyville na Friday: 6259\n"
     ]
    }
   ],
   "source": [
    "number_tracks(df, 'Friday', 'Shelbyville')# a quantidade de músicas tocadas em Shelbyville na sexta-feira\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EgPIHYu_Zcu"
   },
   "source": [
    "**Conclusões**\n",
    "\n",
    "`Comente sobre se a terceira hipótese está correta ou deve ser rejeitada. Explique seu raciocínio.`\n",
    "\n",
    "existem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7nFQajCVw5B"
   },
   "source": [
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykKQ0N65_Zcv"
   },
   "source": [
    "# Conclusões <a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjUwbHb3_Zcv"
   },
   "source": [
    "`Resuma suas conclusões sobre a hipótese aqui`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azLHu64yOIp7"
   },
   "source": [
    "### Importante\n",
    "Em projetos de pesquisas reais, o teste estatístico de hipóteses é mais preciso e quantitativo. Observe também que conclusões sobre uma cidade inteira nem sempre podem ser tiradas a partir de dados de apenas uma fonte.\n",
    "\n",
    "Você aprenderá mais sobre testes de hipóteses no sprint sobre a análise estatística de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju4AHDSgV1FE"
   },
   "source": [
    "[Voltar ao Índice](#back)"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 370,
    "start_time": "2025-02-28T23:02:44.595Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-28T23:02:47.337Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-28T23:03:04.197Z"
   },
   {
    "duration": 182,
    "start_time": "2025-02-28T23:03:12.732Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-28T23:03:57.670Z"
   },
   {
    "duration": 111,
    "start_time": "2025-02-28T23:04:14.608Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-28T23:04:19.228Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-28T23:04:32.649Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-28T23:06:19.837Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-28T23:14:26.324Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-28T23:16:40.216Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-28T23:16:46.054Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-28T23:17:51.602Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-28T23:20:25.006Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-28T23:20:28.599Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-28T23:20:56.249Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-28T23:25:29.624Z"
   },
   {
    "duration": 19,
    "start_time": "2025-02-28T23:29:46.800Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-28T23:29:56.230Z"
   },
   {
    "duration": 26,
    "start_time": "2025-02-28T23:34:25.676Z"
   },
   {
    "duration": 45,
    "start_time": "2025-02-28T23:35:14.838Z"
   },
   {
    "duration": 71,
    "start_time": "2025-02-28T23:36:53.262Z"
   },
   {
    "duration": 52,
    "start_time": "2025-02-28T23:37:22.991Z"
   },
   {
    "duration": 527,
    "start_time": "2025-02-28T23:38:52.429Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-28T23:39:43.333Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-28T23:41:40.653Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-28T23:41:51.435Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-28T23:42:10.121Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-28T23:42:39.310Z"
   },
   {
    "duration": 128,
    "start_time": "2025-02-28T23:48:22.069Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-28T23:49:51.230Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-28T23:50:13.500Z"
   },
   {
    "duration": 275,
    "start_time": "2025-02-28T23:59:53.776Z"
   },
   {
    "duration": 42,
    "start_time": "2025-03-01T00:00:47.673Z"
   },
   {
    "duration": 41,
    "start_time": "2025-03-01T00:05:52.049Z"
   },
   {
    "duration": 42,
    "start_time": "2025-03-01T00:09:13.636Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-01T00:11:45.984Z"
   },
   {
    "duration": 45,
    "start_time": "2025-03-01T00:13:10.461Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-01T00:13:29.720Z"
   },
   {
    "duration": 40,
    "start_time": "2025-03-01T00:29:55.611Z"
   },
   {
    "duration": 451,
    "start_time": "2025-03-01T12:00:09.116Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-01T12:00:21.032Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-01T12:02:44.256Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-01T12:10:18.417Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-01T12:10:35.784Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-01T12:12:19.540Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-01T12:16:24.105Z"
   },
   {
    "duration": 439,
    "start_time": "2025-03-01T12:18:20.837Z"
   },
   {
    "duration": 127,
    "start_time": "2025-03-01T12:18:39.898Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-01T12:19:14.814Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-01T12:19:32.531Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-01T12:19:41.273Z"
   },
   {
    "duration": 133,
    "start_time": "2025-03-01T12:19:53.913Z"
   },
   {
    "duration": 99,
    "start_time": "2025-03-01T12:25:18.954Z"
   },
   {
    "duration": 129,
    "start_time": "2025-03-01T12:27:43.775Z"
   },
   {
    "duration": 91,
    "start_time": "2025-03-01T12:31:27.230Z"
   },
   {
    "duration": 171,
    "start_time": "2025-03-03T16:59:04.029Z"
   },
   {
    "duration": 367,
    "start_time": "2025-03-03T16:59:07.095Z"
   },
   {
    "duration": 108,
    "start_time": "2025-03-03T16:59:07.574Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-03T16:59:07.980Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-03T20:51:59.229Z"
   },
   {
    "duration": 902,
    "start_time": "2025-03-03T20:58:32.072Z"
   },
   {
    "duration": 295,
    "start_time": "2025-03-03T20:59:29.289Z"
   },
   {
    "duration": 92,
    "start_time": "2025-03-03T20:59:44.098Z"
   },
   {
    "duration": 141,
    "start_time": "2025-03-03T20:59:53.777Z"
   },
   {
    "duration": 91,
    "start_time": "2025-03-03T21:02:38.297Z"
   },
   {
    "duration": 91,
    "start_time": "2025-03-03T21:02:43.143Z"
   },
   {
    "duration": 92,
    "start_time": "2025-03-03T21:02:59.094Z"
   },
   {
    "duration": 92,
    "start_time": "2025-03-03T21:03:01.904Z"
   },
   {
    "duration": 90,
    "start_time": "2025-03-03T21:03:10.420Z"
   },
   {
    "duration": 54,
    "start_time": "2025-03-03T21:03:19.093Z"
   },
   {
    "duration": 953,
    "start_time": "2025-03-03T22:36:52.035Z"
   },
   {
    "duration": 133,
    "start_time": "2025-03-03T22:38:26.938Z"
   },
   {
    "duration": 133,
    "start_time": "2025-03-03T22:39:34.421Z"
   },
   {
    "duration": 130,
    "start_time": "2025-03-03T22:39:37.086Z"
   },
   {
    "duration": 321,
    "start_time": "2025-03-03T22:43:31.488Z"
   },
   {
    "duration": 127,
    "start_time": "2025-03-03T22:45:16.078Z"
   },
   {
    "duration": 129,
    "start_time": "2025-03-03T22:45:21.776Z"
   },
   {
    "duration": 126,
    "start_time": "2025-03-03T22:45:53.968Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-03T22:48:25.106Z"
   },
   {
    "duration": 141,
    "start_time": "2025-03-03T22:48:40.892Z"
   },
   {
    "duration": 125,
    "start_time": "2025-03-03T22:49:37.139Z"
   },
   {
    "duration": 125,
    "start_time": "2025-03-03T22:50:06.171Z"
   },
   {
    "duration": 104,
    "start_time": "2025-03-03T22:50:16.048Z"
   },
   {
    "duration": 127,
    "start_time": "2025-03-03T22:51:16.309Z"
   },
   {
    "duration": 130,
    "start_time": "2025-03-03T22:55:40.738Z"
   },
   {
    "duration": 129,
    "start_time": "2025-03-03T23:01:10.086Z"
   },
   {
    "duration": 42,
    "start_time": "2025-03-03T23:09:24.141Z"
   },
   {
    "duration": 44,
    "start_time": "2025-03-03T23:10:18.853Z"
   },
   {
    "duration": 44,
    "start_time": "2025-03-03T23:12:40.047Z"
   },
   {
    "duration": 40,
    "start_time": "2025-03-03T23:12:55.053Z"
   },
   {
    "duration": 43,
    "start_time": "2025-03-03T23:13:11.043Z"
   },
   {
    "duration": 44,
    "start_time": "2025-03-03T23:14:44.556Z"
   },
   {
    "duration": 42,
    "start_time": "2025-03-03T23:14:50.619Z"
   },
   {
    "duration": 88,
    "start_time": "2025-03-03T23:15:23.842Z"
   },
   {
    "duration": 130,
    "start_time": "2025-03-03T23:16:34.033Z"
   },
   {
    "duration": 128,
    "start_time": "2025-03-03T23:17:24.227Z"
   },
   {
    "duration": 127,
    "start_time": "2025-03-03T23:17:40.817Z"
   },
   {
    "duration": 128,
    "start_time": "2025-03-03T23:18:45.300Z"
   },
   {
    "duration": 90,
    "start_time": "2025-03-03T23:23:34.399Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-03T23:24:38.310Z"
   },
   {
    "duration": 99,
    "start_time": "2025-03-03T23:26:34.612Z"
   },
   {
    "duration": 99,
    "start_time": "2025-03-03T23:26:44.907Z"
   },
   {
    "duration": 101,
    "start_time": "2025-03-03T23:26:50.615Z"
   },
   {
    "duration": 100,
    "start_time": "2025-03-03T23:30:09.221Z"
   },
   {
    "duration": 98,
    "start_time": "2025-03-03T23:30:12.688Z"
   },
   {
    "duration": 1037,
    "start_time": "2025-03-03T23:30:45.314Z"
   },
   {
    "duration": 105,
    "start_time": "2025-03-03T23:31:31.929Z"
   },
   {
    "duration": 99,
    "start_time": "2025-03-03T23:31:46.929Z"
   },
   {
    "duration": 96,
    "start_time": "2025-03-03T23:33:54.511Z"
   },
   {
    "duration": 112,
    "start_time": "2025-03-03T23:42:19.412Z"
   },
   {
    "duration": 93,
    "start_time": "2025-03-04T00:18:35.753Z"
   },
   {
    "duration": 91,
    "start_time": "2025-03-04T00:18:55.950Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-04T00:20:22.937Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-04T00:20:32.740Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-04T00:20:44.845Z"
   },
   {
    "duration": 94,
    "start_time": "2025-03-04T00:20:56.155Z"
   },
   {
    "duration": 91,
    "start_time": "2025-03-04T00:21:47.524Z"
   },
   {
    "duration": 145,
    "start_time": "2025-03-04T00:22:30.974Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-04T00:25:15.088Z"
   },
   {
    "duration": 89,
    "start_time": "2025-03-04T00:25:20.488Z"
   },
   {
    "duration": 94,
    "start_time": "2025-03-04T00:27:22.564Z"
   },
   {
    "duration": 100,
    "start_time": "2025-03-04T00:29:11.836Z"
   },
   {
    "duration": 90,
    "start_time": "2025-03-04T00:29:32.211Z"
   },
   {
    "duration": 91,
    "start_time": "2025-03-04T00:29:35.192Z"
   },
   {
    "duration": 92,
    "start_time": "2025-03-04T00:30:59.816Z"
   },
   {
    "duration": 53,
    "start_time": "2025-03-04T00:32:48.388Z"
   },
   {
    "duration": 89,
    "start_time": "2025-03-04T00:41:54.380Z"
   },
   {
    "duration": 91,
    "start_time": "2025-03-04T00:42:02.009Z"
   },
   {
    "duration": 112,
    "start_time": "2025-03-04T00:42:58.107Z"
   },
   {
    "duration": 92,
    "start_time": "2025-03-04T00:44:37.699Z"
   },
   {
    "duration": 111,
    "start_time": "2025-03-04T00:45:21.386Z"
   },
   {
    "duration": 92,
    "start_time": "2025-03-04T00:45:51.284Z"
   },
   {
    "duration": 93,
    "start_time": "2025-03-04T00:47:06.905Z"
   },
   {
    "duration": 93,
    "start_time": "2025-03-04T00:47:19.717Z"
   },
   {
    "duration": 100,
    "start_time": "2025-03-04T00:47:41.850Z"
   },
   {
    "duration": 93,
    "start_time": "2025-03-04T00:49:15.291Z"
   },
   {
    "duration": 92,
    "start_time": "2025-03-04T00:49:20.408Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-04T00:50:49.865Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-04T00:50:58.816Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-04T00:51:34.586Z"
   },
   {
    "duration": 94,
    "start_time": "2025-03-04T00:51:42.214Z"
   },
   {
    "duration": 94,
    "start_time": "2025-03-04T00:53:48.987Z"
   },
   {
    "duration": 93,
    "start_time": "2025-03-04T00:57:06.222Z"
   },
   {
    "duration": 102,
    "start_time": "2025-03-04T00:59:16.387Z"
   },
   {
    "duration": 63,
    "start_time": "2025-03-04T00:59:21.237Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-04T01:12:03.890Z"
   },
   {
    "duration": 102,
    "start_time": "2025-03-04T01:13:47.510Z"
   },
   {
    "duration": 126,
    "start_time": "2025-03-04T01:15:12.487Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-04T01:16:40.761Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-04T01:16:46.413Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-04T01:16:55.059Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-04T01:17:03.400Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-04T01:17:05.192Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-04T01:17:55.166Z"
   }
  ],
  "colab": {
   "collapsed_sections": [
    "E0vqbgi9ay0H",
    "VUC88oWjTJw2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
